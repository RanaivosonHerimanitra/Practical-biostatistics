--- 
title: "Practical Biostatistics"
author: "Herimanitra RANAIVOSON"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
#bibliography: [book.bib, packages.bib]
#biblio-style: apalike
link-citations: yes
github-repo: RanaivosonHerimanitra/Practical-biostatistics
description: "A curated list of resources for statisticians, social scientists, biologists, students involved in data analysis and interpretation tasks such as inferential statistics, Bioinformatics. All with straightforward application using R and/or Python programming languages."
---

# About this book:

A curated list of resources for statisticians, social scientists, biologists, students involved in data analysis and interpretation tasks such as inferential statistics, Bioinformatics. All with straightforward application using R and/or Python programming languages.

# Probability distribution


Statisticians never start out knowing the average in the population. They use sampling 
distribution to infer **parameters** of the population. 

## The jargon:

Within a sample, we can calculate a statistic and get its _standard deviation_ which is also called _standard error_ . _standard deviation_ reflects the **spread** of the distribution of the statistics we are interested in.

We can do more with our sample by guessing its confident interval. A numerical interval from within which **true** parameters should fluctuate by calculating what we call _standard error_ by the following formula:

$$ SE=\sigma/\sqrt{n} $$

In case of proportion (our statistics of interest), _standard error_ can be written as follows:

$$ SE=\sqrt{ p(1-p) / n }  $$

where standard deviation of a binomial proportion is:

$$ \sigma = \sqrt {p(1-p)} $$

## Law of large number and the Central Limit Theorem 

## Binomial distribution

## Exponential distribution:

This kind of this distribution is used for survival analysis. Its probability distribution with parameter $\lambda$ is written as follows:

$$ P(X=t)= \lambda e^{-\lambda t} $$

and its cumulative distribution function (CDF) for $\lambda=1$ is:

$$ P(X \leq A)= \int_0^A e^{-t}dt $$ 

In a graph, the CDF looks like this:

```{r,echo=F}
x=seq(0.0,15.0,by=0.5)
y= exp(-x) -1
plot(x,y,"l")
```

* Application:

Suppose that survival drops off rapidly in the year following diagnosis of a certain type of advanced cancer. Suppose that the length of survival (time-to-death) is a random variable that approximately follows an _exponential distribution_ with $\lambda= 2$ .

Probability distribution is : $P(X=t)= 2e^{-2t}$

*Question* : What is the probability that a person who is diagnosed with this illness will survives a year?

The probability of dying within one year can be calculated using the CDF:

$$ P(X \leq 1)= 1- e^{-2} $$ 

The chance of surviving past one (01) year is: $P(X \ge 1)=1-P(X \leq 1)=13.5$


## Normal distribution

## Assessing normality in data


# Type of uncertainty and statistical power:

Statistical power is the dark side of sample size calculation. Survey statisticians often get confused because they used to apply classical sampling theories drawn from survey design methodologies (strata allocation, multistage sampling,etc.) whereas Biostatisticians are more likely to encounter the former when designing their randomized controlled trial studies. As a Biostatistician, you need to master both as health studies may be observational as well as experimental like RCT. So what is statistical power ?

When designing an experiment, one needs to define hypotheses testing:

* A null hypothesis ( either an hypothesis that is more likely to appear either an hypothesis we want to test against ) and

* An alternative hypothesis

Once, they are defined, you can predict the range of values for your statistics of interest that you expect to see if the null hypothesis is true. After data collection, you calculate your statistics and its <code>p-value</code>. If <code>p-value</code> is small enough (let's say less than 5%), you encounter a statistics that is not expect (because It is less than 5%) based on null hypothesis an vice versa.
The statistical power is the probability of finding true effect when It actually exists. It directly relates to incertainty during our decision to reject or not the null hypothesis.

**Summary:**

The probability to reject the _null hypothesis_ when an _alternative hypothesis_ is true, under a certain study conditions, is then called power of a statistical test. Suppose we are a given statistic on mean weight (55 kg) of population in a given village. We are interested in a nutritional survey that concerns people with a mean weight of 50 with a standard deviation of 5kg. We randomly sampled 35 people and then asked to find true population mean of 50 at the 5% level of significance. The probability associated with this level of confidence is called **_statistical power_**.



# Overview of statistical tests:


Choosing the right test or analysis may sound tricky. This chapter attempts to bridge the gap by trying to gather most commonly used statistical tests and suitable analysis for a given statistical works.

In fact, the choice of analysis depends on 03 parts:

 * based on type of outcome variable(s): continuous, categorical, time-to-event
 
 * based on independance between variables (covariates, outcome)
 
 * based on distribution of data (outcome variable(s))
 
This table provides a summary of main analysis that could be performed stratified by previous factors:

```{r,echo=F,out.extra='',comment='', message=FALSE , warning=FALSE}

df=data.frame(Outcome=c("Continuous","Binary or Categorical","Time-to-event"),
              Independant=c("t-test, ANOVA, Linear correlation, Linear regression",
                      "Odds-ratio/relative risks, Chi2 test, Multinomial/Logistic regression",
                      "Kaplan-Meier, Cox regression"),
              Correlated =c("Paired t-test, repeated measures ANOVA, mixed models/GEE modeling","McNemar test,GEE modeling","Frailty model"),
             
              Alternatives=c("When standard assumption is violated, use wilcoxon rank-sum test, wilcoxon sign-rank test, Kruskall-Wallis test, Spearman rank test, correlation coefficient","When standard assumption is violated, use Fisher exact test, McNemar exact test","Time-varying effects"))
knitr::kable(df,caption="Summary of statistical test and analysis")
```

# Usual Statistical tests:

## Comparison of proportions:

**Context:**

We would like to draw conclusion on 02 population proportions $$ D=p{1} - p{2} $$ 

For example, we may want to know if proportion of Malaria occurrence in Rural area is significantly different from urban one. All we need to do is to build a confidence interval for $$ D $$ then make our conclusion. Our confidence interval relies on normal distribution of the difference between the 02 proportions under certain conditions which must be fulfilled:

(1) $$ n{1}p{1}>10 $$ 

(2) $$ n{1}(1-p{1})>10 $$ 

(3) $$ n{2}p{2}>10 $$ 

(4) $$ n{2}(1-p{2})>10 $$

### Chisquare test

### Fisher exact test

### Mantel-Haenszel test

## Comparison of means:

### student t-test:

## Comparison of medians:

### Wilcoxon test:
Is used when comparing an observed median with a theoretical one.

### Mann-Whitney test:

Is used when comparing two observed medians

### Kruskall-Wallis test:
Is used to compare at least 02 observed medians.

## Comparison of variances:

### Fisher-Snedecor and Ansari-Bradley tests:
Are used to compare two observed variance.

### Bartlett and Fligner- Killeen tests:
Are used to compare at least 02 observed variances.

## Comparison of distribution:

### Chisquare goodness of fit:
Adequation of a sampling distribution to a theoretical one.

### Kolmogorov-Smirnov test:
Adequation of a sampling distribution to a theoretical one.

### Shapiro-Wilk test:
Adequation of a sampling distribution to a theoretical one.

# Non parametric versus parametric test approach:

Non parametric tests approach construct statistic test based on the sample distribution and don't rely on any parameters that describe the population as opposed to parametric test which state that population distribution can be summarized by numerical parameters. One such example is the **Kruskall Wallis test** which is an alternative to ANOVA when sample size is small but also when normality assumption is violated.

## Different types of variables association:

Depending on types of variables, we may encounter 03 cases:

* When variables are quantitative variables, we use coefficient of correlation to measure their association. 03 outcomes are possible: negatively correlated(-1), positively correlated (+1) and no correlation (0).

* When variables are categorical, we use chi square distribution to measure their distance compared to an independence situation.

In case we have mixture of both types, we use variance analysis mainly using correlation





# Study design in traditional surveys:

## Unequal Probabilities Sampling

## Stratified Random Sampling

 * Stratification proportional to size

 * Neymar Optimal allocation 
 


## Multistage Random Sampling

# Study design in clinical trials:

## Overview of Clinical Trials
 * Introduction
 * Phases of Clinical Trials and Objectives
 * The Clinical Development Plan
 * Biostatistical Aspects of a Protocol


## Treatment Comparisons in Clinical Trials
 * Data from Clinical Trials
 * Statistical Models for Treatment Comparisons
 * application using R
 
## Treatment Comparisons in Clinical Trials with Covariates
 * Data from Clinical Trials
 * Statistical Models Incorporating Covariates
 * application using R
 
## Analysis of Clinical Trials with Time-to-Event Endpoints
 * Clinical Trials with Time-to-Event Data
 * Statistical Models
 * Statistical Methods for Right-Censored Data
 * Statistical Methods for Interval-Censored Data
 * Step-by-Step Implementations in R

## Analysis of Data from Longitudinal Clinical Trials
 * Clinical Trials
 * Statistical Models
 * Analysis of Data from Longitudinal Clinical Trials

## Meta-Analysis of Clinical Trials
 * Data from Clinical Trials
 * Statistical Models for Meta-Analysis
 * Meta-Analysis of Data in R

## Bayesian Analysis Methods in Clinical Trials
* Bayesian Models
* R Packages in Bayesian Modeling
* MCMC Simulations
* Bayesian Data Analysis

## Analysis of Bioequivalence Clinical Trials
* Data from Bioequivalence Clinical Trials
* Bioequivalence Clinical Trial Endpoints
* Statistical Methods to Analyze Bioequivalence
* Step-by-Step Implementation in R

## Analysis of Adverse Events in Clinical Trials
 * Adverse Event Data from a Clinical Trial
 * Statistical Methods
 * Step-by-Step Implementation in R

## Analysis of DNA Microarrays in Clinical Trials
 * DNA Microarray
 * Breast Cancer Data

## Sample Size Determination and Power Calculation in Clinical Trials
* Prerequisites for Sample Size Determination:
Sample size determination is key in trial design. In fact, a well designed trial is a trial that has required sample size to detect clinically meaningful difference between treatment groups.
In most randomized trial, the goal is to demonstrate the _superiority_ of a new regimen (new treatment) with respect to standard or existing one.
Clinical trial can be divided in 02 groups depending on their goal:

* Superiority trial which attempts to demonstrate the _superiority_ of a new treatment as previously stated.

* Non inferiority trial which attempts to demonstrate the _equivalence_ of let's say 02 concurrent treatments.

### Considerations Prior to Sample Size Calculation
*  Confounding and Interaction
*  One-Sided Test versus Two-Sided Test
*  Crossover Design versus Parallel Design
*  Subgroup/Interim Analyses
*  Data Transformation
*  Practical Issues

### Comparing Means
*  One-Sample Design
*  Two-Sample Parallel Design
*  Two-Sample Crossover Design
*  Multiple-Sample One-Way ANOVA
*  Multiple-Sample Williams Design


### Large Sample Tests for Proportions
*  One-Sample Design
*  Two-Sample Parallel Design
*  Two-Sample Crossover Design
*  One-Way Analysis of Variance
*  Williams Design
*  Relative Risk—Parallel Design
*  Relative Risk—Crossover Design



### Exact Tests for Proportions
*  Binomial Test
*  Fisher’s Exact Test
*  Optimal Multiple-Stage Designs for Single Arm Trials
*  Flexible Designs for Multiple-Arm Trials

### Tests for Goodness-of-Fit and Contingency Tables
*  Tests for Goodness-of-Fit
*  Test for Independence—Single Stratum
*  Test for Independence—Multiple Strata
*  Test for Categorical Shift
*  Carry-Over Effect Test


### Comparing Time-to-Event Data
*  Basic Concepts
*  Exponential Model
*  Cox’s Proportional Hazards Model
*  Weighted Log-Rank Test

### Group Sequential Methods
* Pocock’s Test
* O’Brien and Fleming’s Test
* Wang and Tsiatis’ Test
* Inner Wedge Test
* Binary Variables
* Time-to-Event Data
* Alpha Spending Function
* Sample Size Re-Estimation
* Conditional Power

### Comparing Variabilities
*  Comparing Intra-Subject Variabilities
*  Comparing Intra-Subject CVs
*  Comparing Inter-Subject Variabilities
*  Comparing Total Variabilities

### Bioequivalence Testing
*  Bioequivalence Criteria
*  Average Bioequivalence
*  Population Bioequivalence
*  Individual Bioequivalence
*  In Vitro Bioequivalence

### Dose Response Studies
*  Continuous Response
*  Binary Response
*  Time-to-Event Endpoint
*  Williams’ Test for Minimum Effective Dose (MED)
*  Cochran–Armitage’s Test for Trend
*  Dose Escalation Trials

### Microarray Studies
*  Literature Review
*  False Discovery Rate (FRD) Control
*  Family-Wise Error Rate (FWER) Control


### Bayesian Sample Size Calculation
*  Posterior Credible Interval Approach
*  Posterior Error Approach
*  The Bootstrap-Median Approach


### Nonparametrics
*  Violation of Assumptions
*  One-Sample Location Problem
*  Two-Sample Location Problem
*  Test for Independence


### Sample Size Calculation in Other Areas
*  QT/QTc Studies with Time-Dependent Replicates
*  Propensity Analysis in Nonrandomized Studies
*  ANOVA with Repeated Measures
*  Quality of Life
*  Bridging Studies
*  Vaccine Clinical Trials



















# Statistical modelling and data analysis in Epidemiology (clinical trials):

# Application in development economics:

## Linear regression and how to interpret results:

### multiple linear regression:

Is used to jointly assess effects of multiple covariates on an outcome.???

## logistic regression and odds-ratio :

* Crude odds-ratio
* Don't forget to mention formula of Mantel-Haenszel 
* Confidence interval for odds-ratio
* Propensity score matching: can be useful when controlling for multiple confounders because it combines candidate confounders into a single summary score. Distinguish cases depending on type of  [https://courses.edx.org/courses/HarvardX/PH207x/2012_Fall/courseware/Week_10/week10:epi10/](studies).

* Classification using logistic regression (Sensitivity: is the capacity of a statistical test to detect true when It's observed to be true (in reality).)

### Instrumental variables and confounders:

## Cox proportional hazard regression:

When we study a cohort of patients

## Machine Learning in public health:


```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```
